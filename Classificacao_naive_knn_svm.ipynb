{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d8a4a9",
   "metadata": {},
   "source": [
    "# Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c798ca",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b875b7c",
   "metadata": {},
   "source": [
    "É um classificador probabilistico baseado no teorema de Bayes que seria a probabilidade de ocorrer um evento \"A\" dado o evento \"B\" é a probabilidade de \"A\" em \"B\", vezes a probabilidade de \"A\", dividida pela probabilidade de \"B\".\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A)*P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Ex: Qual a probabilidade de se ter cancer aos 65 anos, sabendo que a probabilidade de ter cancer independente da idade é de 1%, a probabilidade de se ter 65 anos é 0,2% e dentre as pessoas que tem cancer, as que possuem 65 anos representam 0,5%?\n",
    "\n",
    "$ P(A) = 1\\%$, $ P(B) = 0,2\\%$, $ P(B|A) = 0,5\\%$ \n",
    "\n",
    "Em classificação:\n",
    "\n",
    "$$\n",
    "    P(C_i|X) = \\frac{P(X|C_i)*P(C_i)}{P(X)}\n",
    "$$\n",
    "\n",
    "No qual $C_i$ é uma classe e $X$ a entrada dada por:\n",
    "$$\n",
    "X = {x_1, x_2, x_3, \\:...\\:, x_n}\n",
    "$$\n",
    "\n",
    "Com isso, a probabilidade de $P(X|C_i)$ é o probatório de todas as entradas separadamente e a probablilidade final é o valor do probatório normalizado de 0 à 1, ou seja:\n",
    "\n",
    "$$\n",
    "P(X|C_i) = (P(x_1|C_i)) * (P(x_2|C_i)) * (P(x_3|C_i)) \\:...\\: * (P(x_n|C_i))\n",
    "$$\n",
    "\n",
    "Para atributos discretos, a probabilidade é simples, dado por:\n",
    "\n",
    "$$\n",
    "P(X_i|C_i) = \\frac{qtd\\: de\\: x_i\\: que\\: deram\\: C_i}{qtd\\:de\\:C_i}\n",
    "$$\n",
    "\n",
    "\n",
    "Para atributos contínuos, a probabilidade é dada pela função de probabilidade de distribuição, **geralmente utilizada a distribuição normal**.\n",
    "\n",
    "<img src = 'imagens_classificacao/naive.png'>\n",
    "\n",
    "\n",
    "<img src = 'imagens_classificacao/naive2.png'>\n",
    "\n",
    "\n",
    "### Estimador de Laplace\n",
    "   - Caso **todos** os exemplos de uma entrada x resulte em uma saída 1, insere-se um valor fictício tal que x resulte na saida 0, para que não torne necessariamente uma resposta direta de x para y. Ou seja, 99% de chances de x gerar 1, mas não 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c038e9",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae73d2",
   "metadata": {},
   "source": [
    "O algoritmo do KNN (k-Nearest Neighbors) é um algoritmo simples muito parecido com o K-means, porém supervisonado, no qual o resultado do algoritmo é baseado na distância em referência dos seus vizinhos por classe, dada por:\n",
    "\n",
    "$$\n",
    "C_1voto_{k\\:vizinhos} = \\sum{\\frac{1}{dist(k_{vizinho1},x)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_2voto_{k\\:vizinhos} = \\sum{\\frac{1}{dist(k_{vizinho2},x)}}\n",
    "$$\n",
    "\n",
    "\n",
    "A entrada é atribuida à classe que gerar maior valor resultante, no qual, em caso de empata, cai na região 'vazia'\n",
    "\n",
    "- Por lidar com distâncias, é muito **importante normalizar** os dados por conta das diferênças de escala dos atributos\n",
    "\n",
    "<img src = 'imagens_classificacao/knn.png'>\n",
    "\n",
    "\n",
    "<img src = 'imagens_classificacao/knn2.png'>\n",
    "\n",
    "\n",
    "Em geral, para um valor de K pequeno, o KNN se ajusta mais ao dataset de treino, uma vez que irá levar apenas ao mais próximo, porém não fica extremamente sensível à ruido, para casos onde foi colocado uma saida de maneira errada no dataset\n",
    "\n",
    "\n",
    "\n",
    "## Para Regressão\n",
    "\n",
    "A saída da classe é a média ou a média ponderada das saídas dos k vizinhos mais próximos, levando a distância como parâmetro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec94678",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf6588b",
   "metadata": {},
   "source": [
    "Suporte Vector Machine é um algorítimo que tenta separar classes linearmente separáveis, maximizando a margem que separa as classes, utilizando os dados mais próximos dessa linha de separação como \"vetores de suporte\".\n",
    "\n",
    "<img src = 'imagens_classificacao/svm.png'>\n",
    "\n",
    "Pensando justamente nos dados reais, existe o Soft SVM, o qual permite um erro para ajustar a melhor reta de separação\n",
    "\n",
    "Para conjutos de dados não separáveis linearmente, é utlizado a função de Kernel, aumentando o número de dimensões, no qual:\n",
    "\n",
    "$$\n",
    "K(x) = <h(x), h(x´)>\n",
    "$$\n",
    "\n",
    "\n",
    "<img src = 'imagens_classificacao/kernel1.png'>\n",
    "\n",
    "\n",
    "<img src = 'imagens_classificacao/kernel.png'>\n",
    "\n",
    "\n",
    "Para SVM multiclasses, o número de hiperplanos separando os dados é o mesmo que o número de classes, no qual, para cada classe é gerando um SVM diferente.\n",
    "\n",
    "\n",
    "<img src = 'imagens_classificacao/svm_multiclasses1.png'>\n",
    "<img src = 'imagens_classificacao/svm_multiclasses.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
